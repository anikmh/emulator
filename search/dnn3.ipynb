{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 13:38:12.742378: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-14 13:38:12.751785: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-14 13:38:12.754593: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', size=12.0)\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "import keras_tuner as kt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory growth enabled for the first GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1731609494.175230 3387769 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1731609494.213496 3387769 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1731609494.214797 3387769 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "tuner_dir = 'trials3'\n",
    "\n",
    "if os.path.exists(tuner_dir):\n",
    "    shutil.rmtree(tuner_dir)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        print(\"Memory growth enabled for the first GPU.\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Could not enable memory growth: {e}\")\n",
    "else:\n",
    "    print(\"No GPUs found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ['nl']\n",
    "label = ['NL']\n",
    "x_names = ['a', 'alpha', 'param_S', 'param_L', '', 'trans1',\n",
    "           '', 'trans2', '', 'M_chirp_det', 'q', 'z_cdf']\n",
    "for k in range(len(model)):\n",
    "    if model[k] == 'mp' or model[k] == 'np':\n",
    "        x_names[4], x_names[6], x_names[8] = 'exp1', 'exp2', 'exp3'\n",
    "    else:\n",
    "        x_names[4], x_names[6], x_names[8] = 'csq1', 'csq2', 'csq3'\n",
    "y_names = ['I1', 'I2']\n",
    "\n",
    "# Define file directory and load data\n",
    "dir = '/home/anik/bamr/out/aff_inv/'\n",
    "mchain = h5py.File(dir + 'nl_all', 'r')['markov_chain_0']\n",
    "\n",
    "# Prepare X, Y, Z based on loaded data\n",
    "x_ncols, y_ncols = len(x_names), len(y_names)\n",
    "nrows, data = mchain['nlines'][0], mchain['data']\n",
    "X, Y = np.zeros((x_ncols, nrows)), np.zeros((y_ncols, nrows))\n",
    "\n",
    "for i in range(x_ncols):\n",
    "    X[i] = data[x_names[i]]\n",
    "for i in range(y_ncols):\n",
    "    Y[i] = data[y_names[i]]\n",
    "\n",
    "# Transpose X and Y to shape (nrows, ncols)\n",
    "X, Y = X.T, Y.T\n",
    "\n",
    "scaler_X = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_Y = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Fit-transform X\n",
    "x = scaler_X.fit_transform(X)\n",
    "y = scaler_Y.fit_transform(Y)\n",
    "\n",
    "# Split the data for training and validation as required\n",
    "x_tr, x_ts, y_tr, y_ts = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_ts, x_vl, y_ts, y_vl = train_test_split(x_ts, y_ts, test_size=0.01, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1731609494.274382 3387769 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1731609494.275698 3387769 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1731609494.276723 3387769 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1731609494.412125 3387769 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1731609494.413678 3387769 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1731609494.415504 3387769 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 3, 'max_value': 4, 'step': 1, 'sampling': 'linear'}\n",
      "units_0 (Choice)\n",
      "{'default': 16, 'conditions': [], 'values': [16, 32, 48, 64, 80, 96], 'ordered': True}\n",
      "units_1 (Choice)\n",
      "{'default': 16, 'conditions': [], 'values': [16, 32, 48, 64, 80, 96], 'ordered': True}\n",
      "units_2 (Choice)\n",
      "{'default': 16, 'conditions': [], 'values': [16, 32, 48, 64, 80, 96], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "def build_model(hp):\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Input(shape=(12,)))\n",
    "    \n",
    "    for i in range(hp.Int('num_layers', 3, 4)):\n",
    "        units = hp.Choice(f'units_{i}', [16, 32, 48, 64, 80, 96])\n",
    "        model.add(layers.Dense(units=units, activation='relu'))\n",
    "    \n",
    "    model.add(layers.Dense(units=2, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='mse',\n",
    "        metrics=['mse']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=1000,\n",
    "    executions_per_trial=1,\n",
    "    directory='trials3',\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    restore_best_weights=True,\n",
    "    patience=10\n",
    ")\n",
    "\n",
    "lr_schedule = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.1, \n",
    "    patience=5\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    x_tr, y_tr,\n",
    "    validation_data=(x_ts, y_ts),\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary(num_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the best model and evaluate\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    min_delta=1.0e-6, \n",
    "    patience=10\n",
    ")\n",
    "\n",
    "lr_schedule = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "training = best_model.fit(x_tr, y_tr, epochs=1000, validation_data=(x_ts, y_ts), \\\n",
    "                          batch_size=128, callbacks=[early_stop, lr_schedule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(training.history['loss'], ls='--', color='red', label='train')\n",
    "plt.semilogy(training.history['val_loss'], color='orange', label='test')\n",
    "plt.grid()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title(\"Training History\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume y_pr contains the normalized predictions and y_vl is the validation data\n",
    "y_pr = best_model.predict(x_vl)\n",
    "\n",
    "# Initialize arrays to store denormalized values\n",
    "Y_pr = scaler_Y.inverse_transform(y_pr)\n",
    "Y_vl = scaler_Y.inverse_transform(y_vl)\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(Y_vl[:, 0], label='I1 data', c='g', ls='--')\n",
    "plt.plot(Y_pr[:, 0], label='I1 pred', c='r')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(Y_vl[:, 1], label='I2 data', c='g', ls='--')\n",
    "plt.plot(Y_pr[:, 1], label='I2 pred', c='r')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
