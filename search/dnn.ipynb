{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-30 12:01:13.708567: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-30 12:01:13.718291: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-30 12:01:13.721273: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-30 12:01:13.729378: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', size=12.0)\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import layers, mixed_precision, regularizers\n",
    "import keras_tuner as kt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ['nl']\n",
    "label = ['NL']\n",
    "x_names = ['a', 'alpha', 'param_S', 'param_L', '', 'trans1', '', 'trans2', '']\n",
    "for k in range(len(model)):\n",
    "    if model[k] == 'mp' or model[k] == 'np':\n",
    "        x_names[4], x_names[6], x_names[8] = 'exp1', 'exp2', 'exp3'\n",
    "    else:\n",
    "        x_names[4], x_names[6], x_names[8] = 'csq1', 'csq2', 'csq3'\n",
    "y_names = [f\"R_{i}\" for i in range(100)]\n",
    "\n",
    "dir = '/home/anik/bamr/out/aff_inv/'\n",
    "mchain = h5py.File(dir + 'nl_all', 'r')['markov_chain_0']\n",
    "x_ncols, y_ncols = len(x_names), len(y_names)\n",
    "nrows, data = mchain['nlines'][0], mchain['data']\n",
    "X, Y = np.zeros((x_ncols, nrows)), np.zeros((y_ncols, nrows))\n",
    "\n",
    "for i in range(x_ncols):\n",
    "    X[i] = data[x_names[i]]\n",
    "for i in range(y_ncols):\n",
    "    Y[i] = data[y_names[i]]\n",
    "Z = np.array(data['R_max']).reshape(-1, 1)\n",
    "X, Y = X.T, Y.T\n",
    "\n",
    "scaler_X = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_Y = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_Z = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "x = scaler_X.fit_transform(X)\n",
    "z = scaler_Z.fit_transform(Z)\n",
    "\n",
    "# Mask and scale only non-zero values in Y\n",
    "nz = Y != 0\n",
    "y = np.copy(Y)  # Copy Y to keep the structure with zeros intact\n",
    "y[nz] = scaler_Y.fit_transform(Y[nz].reshape(-1, 1)).flatten()\n",
    "\n",
    "x_tr, x_ts, y_tr, y_ts = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_ts, x_vl, y_ts, y_vl = train_test_split(x_ts, y_ts, test_size=0.01, random_state=42)\n",
    "\n",
    "y_tr2, y_ts2, z_tr, z_ts = train_test_split(y, z, test_size=0.2, random_state=42)\n",
    "y_ts2, y_vl, z_ts, z_vl = train_test_split(y_ts2, z_ts, test_size=0.01, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_dir = 'trials'\n",
    "\n",
    "if os.path.exists(tuner_dir):\n",
    "    shutil.rmtree(tuner_dir)\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730232837.709090  409392 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730232837.765656  409392 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730232837.765962  409392 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730232837.768138  409392 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730232837.768392  409392 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730232837.768618  409392 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730232837.846724  409392 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730232837.847006  409392 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730232837.847252  409392 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-29 16:13:57.847427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5716 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060, pci bus id: 0000:09:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 3\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 64, 'max_value': 512, 'step': 64, 'sampling': 'linear'}\n",
      "units_2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 64, 'max_value': 512, 'step': 64, 'sampling': 'linear'}\n",
      "units_3 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 256, 'step': 64, 'sampling': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Define the DNN model with hyperparameter tuning\n",
    "class DNNHyperModel(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(layers.Input(shape=(x_ncols,)))\n",
    "        model.add(layers.Dense(hp.Int('units_1', min_value=64, max_value=512, \\\n",
    "                                      step=64), activation='relu'))\n",
    "        model.add(layers.Dense(hp.Int('units_2', min_value=64, max_value=512, \\\n",
    "                                      step=64), activation='relu'))\n",
    "        model.add(layers.Dense(hp.Int('units_3', min_value=32, max_value=256, \\\n",
    "                                      step=64), activation='relu'))\n",
    "\n",
    "        # Tunable depth (number of hidden layers)\n",
    "        #for i in range(hp.Int('num_layers', 1, 3)):  # 1 to 3 layers\n",
    "        #    model.add(layers.Dense(hp.Int(f'units_{i}', min_value=32, \\\n",
    "        #                                  max_value=512, step=64), activation='relu'))\n",
    "\n",
    "        model.add(layers.Dense(y_ncols, activation='relu'))\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        return model\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    DNNHyperModel(),\n",
    "    objective='val_mae',\n",
    "    max_trials=100,\n",
    "    executions_per_trial=1,\n",
    "    directory='trials'\n",
    ")\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_mae', \\\n",
    "                                              min_delta=1.0e-6, patience=10)\n",
    "\n",
    "# Print the summary of search space\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 56 Complete [00h 00m 52s]\n",
      "val_mae: 0.004793904721736908\n",
      "\n",
      "Best val_mae So Far: 0.0028404411859810352\n",
      "Total elapsed time: 00h 49m 27s\n",
      "\n",
      "Search: Running Trial #57\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "64                |320               |units_1\n",
      "448               |192               |units_2\n",
      "96                |224               |units_3\n",
      "\n",
      "Epoch 1/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - loss: 0.0157 - mae: 0.0743 - val_loss: 0.0095 - val_mae: 0.0454\n",
      "Epoch 2/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0092 - mae: 0.0438 - val_loss: 0.0087 - val_mae: 0.0409\n",
      "Epoch 3/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0086 - mae: 0.0402 - val_loss: 0.0085 - val_mae: 0.0389\n",
      "Epoch 4/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0085 - mae: 0.0387 - val_loss: 0.0085 - val_mae: 0.0382\n",
      "Epoch 5/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0083 - mae: 0.0377 - val_loss: 0.0079 - val_mae: 0.0355\n",
      "Epoch 6/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0078 - mae: 0.0353 - val_loss: 0.0069 - val_mae: 0.0309\n",
      "Epoch 7/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0068 - mae: 0.0305 - val_loss: 0.0069 - val_mae: 0.0312\n",
      "Epoch 8/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0068 - mae: 0.0304 - val_loss: 0.0069 - val_mae: 0.0306\n",
      "Epoch 9/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0068 - mae: 0.0304 - val_loss: 0.0069 - val_mae: 0.0302\n",
      "Epoch 10/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0068 - mae: 0.0301 - val_loss: 0.0069 - val_mae: 0.0301\n",
      "Epoch 11/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - mae: 0.0300 - val_loss: 0.0069 - val_mae: 0.0301\n",
      "Epoch 12/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0069 - mae: 0.0303 - val_loss: 0.0069 - val_mae: 0.0298\n",
      "Epoch 13/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0068 - mae: 0.0299 - val_loss: 0.0069 - val_mae: 0.0309\n",
      "Epoch 14/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0068 - mae: 0.0298 - val_loss: 0.0069 - val_mae: 0.0300\n",
      "Epoch 15/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0068 - mae: 0.0297 - val_loss: 0.0069 - val_mae: 0.0295\n",
      "Epoch 16/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0068 - mae: 0.0295 - val_loss: 0.0069 - val_mae: 0.0297\n",
      "Epoch 17/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0069 - mae: 0.0296 - val_loss: 0.0069 - val_mae: 0.0298\n",
      "Epoch 18/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0068 - mae: 0.0296 - val_loss: 0.0069 - val_mae: 0.0295\n",
      "Epoch 19/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0068 - mae: 0.0293 - val_loss: 0.0063 - val_mae: 0.0280\n",
      "Epoch 20/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0063 - mae: 0.0272 - val_loss: 0.0063 - val_mae: 0.0275\n",
      "Epoch 21/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0062 - mae: 0.0268 - val_loss: 0.0058 - val_mae: 0.0250\n",
      "Epoch 22/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0058 - mae: 0.0249 - val_loss: 0.0058 - val_mae: 0.0248\n",
      "Epoch 23/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0058 - mae: 0.0248 - val_loss: 0.0058 - val_mae: 0.0252\n",
      "Epoch 24/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0058 - mae: 0.0248 - val_loss: 0.0058 - val_mae: 0.0249\n",
      "Epoch 25/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0057 - mae: 0.0247 - val_loss: 0.0058 - val_mae: 0.0251\n",
      "Epoch 26/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0057 - mae: 0.0243 - val_loss: 0.0054 - val_mae: 0.0228\n",
      "Epoch 27/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0054 - mae: 0.0227 - val_loss: 0.0054 - val_mae: 0.0228\n",
      "Epoch 28/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0053 - mae: 0.0226 - val_loss: 0.0054 - val_mae: 0.0228\n",
      "Epoch 29/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0053 - mae: 0.0228 - val_loss: 0.0054 - val_mae: 0.0227\n",
      "Epoch 30/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0053 - mae: 0.0225 - val_loss: 0.0054 - val_mae: 0.0237\n",
      "Epoch 31/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0053 - mae: 0.0226 - val_loss: 0.0054 - val_mae: 0.0224\n",
      "Epoch 32/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0053 - mae: 0.0224 - val_loss: 0.0054 - val_mae: 0.0234\n",
      "Epoch 33/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0053 - mae: 0.0227 - val_loss: 0.0054 - val_mae: 0.0228\n",
      "Epoch 34/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0051 - mae: 0.0215 - val_loss: 0.0049 - val_mae: 0.0205\n",
      "Epoch 35/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - mae: 0.0182 - val_loss: 0.0032 - val_mae: 0.0169\n",
      "Epoch 36/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0031 - mae: 0.0162 - val_loss: 0.0032 - val_mae: 0.0165\n",
      "Epoch 37/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0031 - mae: 0.0164 - val_loss: 0.0032 - val_mae: 0.0164\n",
      "Epoch 38/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - mae: 0.0162 - val_loss: 0.0032 - val_mae: 0.0162\n",
      "Epoch 39/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0032 - mae: 0.0164 - val_loss: 0.0032 - val_mae: 0.0171\n",
      "Epoch 40/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0031 - mae: 0.0162 - val_loss: 0.0032 - val_mae: 0.0160\n",
      "Epoch 41/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0031 - mae: 0.0161 - val_loss: 0.0032 - val_mae: 0.0166\n",
      "Epoch 42/200\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0031 - mae: 0.0161 - val_loss: 0.0032 - val_mae: 0.0160\n",
      "Epoch 43/200\n",
      "\u001b[1m237/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - mae: 0.0162"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run search with variable batch sizes\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_ts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_ts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mstop_early\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mconda/envs/tfg/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:234\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/mconda/envs/tfg/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:274\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/mconda/envs/tfg/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:239\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 239\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    242\u001b[0m     ):\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    255\u001b[0m         )\n",
      "File \u001b[0;32m~/mconda/envs/tfg/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/mconda/envs/tfg/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[1;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[0;32m~/mconda/envs/tfg/lib/python3.12/site-packages/keras_tuner/src/engine/hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mconda/envs/tfg/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/mconda/envs/tfg/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:344\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_epoch_iterator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_epoch_iterator \u001b[38;5;241m=\u001b[39m TFEpochIterator(\n\u001b[1;32m    335\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m    336\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    342\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    343\u001b[0m     )\n\u001b[0;32m--> 344\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    356\u001b[0m }\n\u001b[1;32m    357\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/mconda/envs/tfg/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/mconda/envs/tfg/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:432\u001b[0m, in \u001b[0;36mTensorFlowTrainer.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    431\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m--> 432\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    433\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_end(step, logs)\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_evaluating:\n",
      "File \u001b[0;32m~/mconda/envs/tfg/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/mconda/envs/tfg/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/mconda/envs/tfg/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/mconda/envs/tfg/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:132\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    130\u001b[0m args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[1;32m    131\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m--> 132\u001b[0m function \u001b[38;5;241m=\u001b[39m \u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/mconda/envs/tfg/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/mconda/envs/tfg/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:239\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    229\u001b[0m lookup_func_type, lookup_func_context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    230\u001b[0m     function_type_utils\u001b[38;5;241m.\u001b[39mmake_canonicalized_monomorphic_type(\n\u001b[1;32m    231\u001b[0m         args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m     )\n\u001b[1;32m    236\u001b[0m )\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 239\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlookup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m      \u001b[49m\u001b[43mlookup_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_func_context\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mconda/envs/tfg/lib/python3.12/site-packages/tensorflow/core/function/polymorphism/function_cache.py:48\u001b[0m, in \u001b[0;36mFunctionCache.lookup\u001b[0;34m(self, function_type, context)\u001b[0m\n\u001b[1;32m     46\u001b[0m context \u001b[38;5;241m=\u001b[39m context \u001b[38;5;129;01mor\u001b[39;00m FunctionContext()\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_dict:\n\u001b[0;32m---> 48\u001b[0m   dispatch_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dispatch_type:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_primary[(context, dispatch_type)]\n",
      "File \u001b[0;32m~/mconda/envs/tfg/lib/python3.12/site-packages/tensorflow/core/function/polymorphism/type_dispatch.py:80\u001b[0m, in \u001b[0;36mTypeDispatchTable.dispatch\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the most specific supertype target if it exists in the table.\"\"\"\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# For known exact matches.\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch_table\u001b[49m:\n\u001b[1;32m     81\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m request\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# For known non-exact matches.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# (self._dispatch cache does not contain exact matches)\u001b[39;00m\n",
      "File \u001b[0;32m~/mconda/envs/tfg/lib/python3.12/site-packages/tensorflow/core/function/polymorphism/function_type.py:456\u001b[0m, in \u001b[0;36mFunctionType.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m--> 456\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mconda/envs/tfg/lib/python3.12/site-packages/tensorflow/core/function/polymorphism/function_type.py:154\u001b[0m, in \u001b[0;36mParameter.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m    150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m ((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkind, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptional,\n\u001b[1;32m    151\u001b[0m            \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_constraint) \u001b[38;5;241m==\u001b[39m (other\u001b[38;5;241m.\u001b[39mname, other\u001b[38;5;241m.\u001b[39mkind, other\u001b[38;5;241m.\u001b[39moptional,\n\u001b[1;32m    152\u001b[0m                                      other\u001b[38;5;241m.\u001b[39mtype_constraint))\n\u001b[0;32m--> 154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mhash\u001b[39m((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkind, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptional, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_constraint))\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run search with variable batch sizes\n",
    "tuner.search(\n",
    "    x_tr, y_tr,\n",
    "    epochs=200,\n",
    "    validation_data=(x_ts, y_ts),\n",
    "    batch_size=32,\n",
    "    callbacks=[stop_early]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in trials/untitled_project\n",
      "Showing 1 best trials\n",
      "Objective(name=\"val_mae\", direction=\"min\")\n",
      "\n",
      "Trial 009 summary\n",
      "Hyperparameters:\n",
      "units_1: 320\n",
      "units_2: 192\n",
      "units_3: 224\n",
      "Score: 0.0028404411859810352\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary(num_trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">61,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">43,232</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">22,500</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m)            │         \u001b[38;5;34m3,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)            │        \u001b[38;5;34m61,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)            │        \u001b[38;5;34m43,232\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m22,500\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">130,564</span> (510.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m130,564\u001b[0m (510.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">130,564</span> (510.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m130,564\u001b[0m (510.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Retrieve the best model and evaluate\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 17:05:16.224175: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_193', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1060/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0102 - mae: 0.0448"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 17:05:21.098318: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_193', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0102 - mae: 0.0448 - val_loss: 0.0038 - val_mae: 0.0207\n",
      "Epoch 2/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0038 - mae: 0.0207 - val_loss: 0.0038 - val_mae: 0.0207\n",
      "Epoch 3/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0037 - mae: 0.0195 - val_loss: 0.0037 - val_mae: 0.0188\n",
      "Epoch 4/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0037 - mae: 0.0192 - val_loss: 0.0037 - val_mae: 0.0190\n",
      "Epoch 5/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0034 - mae: 0.0177 - val_loss: 0.0033 - val_mae: 0.0167\n",
      "Epoch 6/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0032 - mae: 0.0166 - val_loss: 0.0028 - val_mae: 0.0160\n",
      "Epoch 7/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0027 - mae: 0.0142 - val_loss: 0.0027 - val_mae: 0.0135\n",
      "Epoch 8/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0027 - mae: 0.0140 - val_loss: 0.0027 - val_mae: 0.0139\n",
      "Epoch 9/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0027 - mae: 0.0140 - val_loss: 0.0027 - val_mae: 0.0138\n",
      "Epoch 10/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0027 - mae: 0.0139 - val_loss: 0.0027 - val_mae: 0.0137\n",
      "Epoch 11/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0026 - mae: 0.0140 - val_loss: 0.0021 - val_mae: 0.0112\n",
      "Epoch 12/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0015 - mae: 0.0098 - val_loss: 0.0012 - val_mae: 0.0080\n",
      "Epoch 13/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0081 - val_loss: 0.0012 - val_mae: 0.0084\n",
      "Epoch 14/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0083 - val_loss: 0.0012 - val_mae: 0.0086\n",
      "Epoch 15/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0084 - val_loss: 0.0012 - val_mae: 0.0081\n",
      "Epoch 16/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0083 - val_loss: 0.0012 - val_mae: 0.0089\n",
      "Epoch 17/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0012 - mae: 0.0081 - val_loss: 0.0012 - val_mae: 0.0081\n",
      "Epoch 18/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0012 - mae: 0.0082 - val_loss: 0.0012 - val_mae: 0.0113\n",
      "Epoch 19/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0012 - mae: 0.0082 - val_loss: 0.0012 - val_mae: 0.0075\n",
      "Epoch 20/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0078 - val_loss: 0.0012 - val_mae: 0.0076\n",
      "Epoch 21/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0012 - mae: 0.0080 - val_loss: 0.0012 - val_mae: 0.0081\n",
      "Epoch 22/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0011 - mae: 0.0078 - val_loss: 0.0012 - val_mae: 0.0074\n",
      "Epoch 23/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0078 - val_loss: 0.0012 - val_mae: 0.0084\n",
      "Epoch 24/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0078 - val_loss: 0.0012 - val_mae: 0.0073\n",
      "Epoch 25/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0078 - val_loss: 0.0012 - val_mae: 0.0074\n",
      "Epoch 26/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0078 - val_loss: 0.0012 - val_mae: 0.0079\n",
      "Epoch 27/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0077 - val_loss: 0.0012 - val_mae: 0.0081\n",
      "Epoch 28/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0078 - val_loss: 0.0012 - val_mae: 0.0076\n",
      "Epoch 29/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0011 - mae: 0.0076 - val_loss: 8.2866e-04 - val_mae: 0.0062\n",
      "Epoch 30/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.9697e-04 - mae: 0.0061 - val_loss: 8.1274e-04 - val_mae: 0.0074\n",
      "Epoch 31/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.9682e-04 - mae: 0.0062 - val_loss: 8.0921e-04 - val_mae: 0.0064\n",
      "Epoch 32/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.8426e-04 - mae: 0.0061 - val_loss: 8.1357e-04 - val_mae: 0.0064\n",
      "Epoch 33/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.9029e-04 - mae: 0.0061 - val_loss: 7.9678e-04 - val_mae: 0.0057\n",
      "Epoch 34/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.8515e-04 - mae: 0.0059 - val_loss: 7.9782e-04 - val_mae: 0.0059\n",
      "Epoch 35/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.8800e-04 - mae: 0.0061 - val_loss: 7.9399e-04 - val_mae: 0.0059\n",
      "Epoch 36/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.8818e-04 - mae: 0.0061 - val_loss: 8.2126e-04 - val_mae: 0.0067\n",
      "Epoch 37/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7.9137e-04 - mae: 0.0061 - val_loss: 7.8888e-04 - val_mae: 0.0056\n",
      "Epoch 38/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 7.8845e-04 - mae: 0.0061 - val_loss: 8.1832e-04 - val_mae: 0.0068\n",
      "Epoch 39/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.6915e-04 - mae: 0.0058 - val_loss: 3.1223e-04 - val_mae: 0.0034\n",
      "Epoch 40/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2.8512e-04 - mae: 0.0035 - val_loss: 3.0737e-04 - val_mae: 0.0036\n",
      "Epoch 41/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2.9869e-04 - mae: 0.0036 - val_loss: 3.0494e-04 - val_mae: 0.0032\n",
      "Epoch 42/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.0088e-04 - mae: 0.0037 - val_loss: 3.1137e-04 - val_mae: 0.0038\n",
      "Epoch 43/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2.9651e-04 - mae: 0.0036 - val_loss: 3.2574e-04 - val_mae: 0.0042\n",
      "Epoch 44/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.0202e-04 - mae: 0.0038 - val_loss: 3.2634e-04 - val_mae: 0.0034\n",
      "Epoch 45/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.0728e-04 - mae: 0.0037 - val_loss: 3.0083e-04 - val_mae: 0.0032\n",
      "Epoch 46/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2.9797e-04 - mae: 0.0035 - val_loss: 3.1370e-04 - val_mae: 0.0036\n",
      "Epoch 47/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.0353e-04 - mae: 0.0038 - val_loss: 3.0620e-04 - val_mae: 0.0035\n",
      "Epoch 48/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 2.8374e-04 - mae: 0.0037 - val_loss: 3.2761e-04 - val_mae: 0.0034\n",
      "Epoch 49/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.9361e-04 - mae: 0.0036 - val_loss: 3.0277e-04 - val_mae: 0.0031\n",
      "Epoch 50/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.0760e-04 - mae: 0.0036 - val_loss: 2.9861e-04 - val_mae: 0.0036\n",
      "Epoch 51/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3.0053e-04 - mae: 0.0035 - val_loss: 3.1435e-04 - val_mae: 0.0036\n",
      "Epoch 52/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 2.8947e-04 - mae: 0.0035 - val_loss: 3.1630e-04 - val_mae: 0.0041\n",
      "Epoch 53/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2.9085e-04 - mae: 0.0036 - val_loss: 3.1611e-04 - val_mae: 0.0036\n",
      "Epoch 54/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2.8681e-04 - mae: 0.0033 - val_loss: 3.0188e-04 - val_mae: 0.0032\n",
      "Epoch 55/1000\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.0110e-04 - mae: 0.0035 - val_loss: 3.0230e-04 - val_mae: 0.0035\n"
     ]
    }
   ],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \\\n",
    "                                              min_delta=1.0e-6, patience=5)\n",
    "\n",
    "# Optionally, retrain on the full dataset with optimal hyperparameters\n",
    "training = best_model.fit(x_tr, y_tr, epochs=1000, validation_data=(x_ts, y_ts), \\\n",
    "                          batch_size=8, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Loss MSE=  [0.84126854 0.6732047  0.5660343  0.4907403  0.43516135 0.39357135\n",
      " 0.36076862 0.33513767 0.31374377 0.29551512 0.28023797 0.26782414\n",
      " 0.25644946 0.24699837 0.23940787 0.23360762 0.22864133 0.22501312\n",
      " 0.22270161 0.2201741  0.21902195 0.21818723 0.2175902  0.21780664\n",
      " 0.21773317 0.21838741 0.21885371 0.21996558 0.22099921 0.22221774\n",
      " 0.22300074 0.22471689 0.22592951 0.2277072  0.22914484 0.23068054\n",
      " 0.23217478 0.23365211 0.23519069 0.23672366 0.23808739 0.23977557\n",
      " 0.24091816 0.242222   0.24381511 0.2448359  0.24592908 0.24689385\n",
      " 0.24786167 0.24869536 0.24934402 0.24981041 0.2501401  0.25023514\n",
      " 0.25003523 0.24944891 0.24867293 0.24785525 0.24686837 0.245865\n",
      " 0.24405564 0.24184549 0.23999009 0.23798457 0.23557521 0.22647896\n",
      " 0.22404927 0.21943146 0.2054628  0.16810293 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "loss = best_model.predict(x_vl)\n",
    "print(\"Loss MSE= \", loss[0])\n",
    "\n",
    "# Save the best model\n",
    "best_model.save(\"best_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogy(training.history['loss'], ls='--', color='red', label='train')\n",
    "plt.semilogy(training.history['val_loss'], color='orange', label='test')\n",
    "plt.grid()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title(\"Training History\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume y_pr contains the normalized predictions and y_vl is the validation data\n",
    "y_pr = best_model.predict(x_vl)\n",
    "\n",
    "# Initialize arrays to store denormalized values\n",
    "Y_pr = np.copy(y_pr)\n",
    "Y_vl = np.copy(y_vl)\n",
    "\n",
    "# Process each row individually\n",
    "for i in range(y_pr.shape[0]):\n",
    "    # Step 1: Identify the index of the first negative value in the row\n",
    "    if np.any(y_pr[i] < 0):  # Check if there is any negative value\n",
    "        i_nz = np.where(y_pr[i] < 0)[0][0]\n",
    "        \n",
    "        # Step 2: Set all values after the first negative value to zero\n",
    "        y_pr[i, i_nz:] = 0\n",
    "\n",
    "    # Step 3: Create a mask to identify non-zero values for denormalization\n",
    "    nz_pr = y_pr[i] != 0\n",
    "    nz_dt = y_vl[i] != 0\n",
    "\n",
    "    # Step 4: Apply inverse_transform only on non-zero values\n",
    "    if np.any(nz_pr):  # Check if there are any non-zero values\n",
    "        Y_pr[i, nz_pr] = scaler_Y.inverse_transform(y_pr[i, nz_pr].reshape(-1, 1)).flatten()\n",
    "    if np.any(nz_dt):  # Check if there are any non-zero values in the original validation data\n",
    "        Y_vl[i, nz_dt] = scaler_Y.inverse_transform(y_vl[i, nz_dt].reshape(-1, 1)).flatten()\n",
    "\n",
    "# Plot the results\n",
    "m = np.linspace(0.2, 3.0, 100)\n",
    "for i in range(22):\n",
    "    plt.plot(Y_vl[i], m, label='Data', color='green', linestyle='--')\n",
    "    plt.plot(Y_pr[i], m, label='Predicted', color='red')\n",
    "    plt.xlabel(\"Radius\")\n",
    "    plt.ylabel(\"Mass\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_radius(y_pr):\n",
    "    for i in range(len(y_pr)):\n",
    "        # Get the current predicted radius vector for the i-th sample\n",
    "        radii = y_pr[i]\n",
    "\n",
    "        # Find the last non-zero radius index\n",
    "        i_max = np.min(np.nonzero(radii))\n",
    "\n",
    "        # Step 1: Set all values after the last non-zero value to zero\n",
    "        radii[i_max + 1:] = 0\n",
    "\n",
    "        # Step 2: Linearly interpolate oscillating values between zero and last non-zero\n",
    "        for j in range(i_max - 1, 0, -1):\n",
    "            if radii[j] < 0 or radii[j] > radii[j + 1]:\n",
    "                # Linearly interpolate between j-1 and the last valid non-zero value\n",
    "                radii[j] = (radii[j-1] + radii[j+1]) / 2\n",
    "\n",
    "        # Update the radius vector in the prediction array\n",
    "        y_pr[i] = radii\n",
    "\n",
    "    return y_pr\n",
    "\n",
    "# Assuming y_pr is the predicted radius output from your model\n",
    "y_pr = model.predict(x_vl)\n",
    "print(y_pr[3])\n",
    "y_pr2 = post_process_radius(y_pr)\n",
    "print(y_pr2[3])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
