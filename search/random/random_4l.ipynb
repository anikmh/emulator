{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0877499",
   "metadata": {},
   "source": [
    "## Tuning 3P Model with Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d96b01d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 20:14:27.636479: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "# Keras-related modules\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import keras_tuner as kt\n",
    "from keras_tuner import HyperModel\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1597db04",
   "metadata": {},
   "source": [
    "### 1. Load data from file and prepare to be used for tuning\n",
    "\n",
    "Load the EoS and the $M-R$ curves from processed 3P data files. Next, normalize the data and perform a train-test split as 80-20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aed9c5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the un-normalized data\n",
    "R = np.loadtxt('../data/mrc_4l.txt')\n",
    "P = np.loadtxt('../data/eos_4l.txt')\n",
    "\n",
    "# Normalize the data\n",
    "r = (R - np.min(R)) / (np.max(R) - np.min(R))\n",
    "p = (P - np.min(P)) / (np.max(P) - np.min(P))\n",
    "\n",
    "# Perform train-test split as 80-20\n",
    "x_tr, x_ts, y_tr, y_ts = train_test_split(r, p, test_size=0.2, shuffle=True, random_state=41)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4255128a",
   "metadata": {},
   "source": [
    "### 2. Construct the search space\n",
    "\n",
    "We seek to find the values of hyperparameters that optimizes the DNN for performance and accuracy. The choices of hyperparameters include number of layers, number of neurons/units in each layer, the activation functions on the inner layers and the output layer. \n",
    "\n",
    "Even with less number of hyperparameters, the search space can be large and the process may take a while to complete, depending on their ranges we choose. Therefore, to expedite the tuning, we fix some hyperparameters and search over the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43cab2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space\n",
    "class RegressionHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape    \n",
    "        \n",
    "    def build(self, hp):\n",
    "        model = keras.Sequential()\n",
    "        # Tune the number of layers\n",
    "        for i in range(hp.Int('num_layers', 1, 5)):\n",
    "            model.add(\n",
    "                layers.Dense(\n",
    "                    # Tune number of units separately\n",
    "                    units=hp.Int(f\"units_{i}\", min_value=194, max_value=970, step=97),\n",
    "                    activation='relu'\n",
    "                )\n",
    "            )\n",
    "        model.add(layers.Dense(97, activation='linear'))\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66869458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the input shape\n",
    "input_shape = (x_tr.shape[1],)\n",
    "hypermodel = RegressionHyperModel(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaba9ac",
   "metadata": {},
   "source": [
    "### 3. Initialize search parameters\n",
    "\n",
    "Set values of search parameters and create an early-stopping callback. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06b6a1c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3037909479.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [5]\u001b[0;36m\u001b[0m\n\u001b[0;31m    executions_per_trial=1,    # Number of repeated trials with same hyperparameters\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Initialize the search\n",
    "tuner = kt.RandomSearch(\n",
    "    hypermodel,                # Pass the hypermodel object\n",
    "    objective='val_loss',      # Quantity to monitor during tuning\n",
    "    seed=42,                   # Set reproducibility of randomness\n",
    "    max_trials=5000            # Max number of trials with different hyperparameters\n",
    "    executions_per_trial=1,    # Number of repeated trials with same hyperparameters\n",
    "    directory=\"random_search\", # Set directory to store search results\n",
    "    project_name=\"4l\",         # Set the subdirectory name\n",
    "    overwrite=True             # Choose if previous search results should be ignored\n",
    ")\n",
    "# Set up callback for early stopping \n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=1.0e-6, patience=10)\n",
    "\n",
    "# Print the summary of search space\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09407e0",
   "metadata": {},
   "source": [
    "Now begin tuning the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "468fa136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 00m 05s]\n",
      "val_loss: 0.0009532268741168082\n",
      "\n",
      "Best val_loss So Far: 0.0008079517283476889\n",
      "Total elapsed time: 00h 09m 35s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(x_tr, y_tr, batch_size=1024, epochs=5000, validation_data=(x_ts, y_ts), \\\n",
    "                callbacks=[stop_early], verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98427e32",
   "metadata": {},
   "source": [
    "### 4. Publish search results\n",
    "\n",
    "Print the first few (5-10) top models and then pick the best model by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87c172e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in random/3p-4l\n",
      "Showing 10 best trials\n",
      "Objective(name='val_loss', direction='min')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 194\n",
      "units_1: 970\n",
      "units_2: 970\n",
      "units_3: 873\n",
      "units_4: 291\n",
      "Score: 0.0008079517283476889\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 4\n",
      "units_0: 291\n",
      "units_1: 679\n",
      "units_2: 485\n",
      "units_3: 291\n",
      "units_4: 873\n",
      "Score: 0.0008149743662215769\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 194\n",
      "units_1: 582\n",
      "units_2: 388\n",
      "units_3: 582\n",
      "units_4: 485\n",
      "Score: 0.0008190334774553776\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 582\n",
      "units_1: 291\n",
      "units_2: 388\n",
      "units_3: 873\n",
      "units_4: 485\n",
      "Score: 0.0008266346412710845\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 5\n",
      "units_0: 388\n",
      "units_1: 776\n",
      "units_2: 776\n",
      "units_3: 388\n",
      "units_4: 776\n",
      "Score: 0.0008269138052128255\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 4\n",
      "units_0: 291\n",
      "units_1: 582\n",
      "units_2: 388\n",
      "units_3: 485\n",
      "units_4: 679\n",
      "Score: 0.0008273362764157355\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 485\n",
      "units_1: 776\n",
      "units_2: 873\n",
      "Score: 0.000836519873701036\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 291\n",
      "units_1: 194\n",
      "units_2: 291\n",
      "units_3: 388\n",
      "units_4: 776\n",
      "Score: 0.0008418959332630038\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 4\n",
      "units_0: 194\n",
      "units_1: 679\n",
      "units_2: 582\n",
      "units_3: 582\n",
      "units_4: 873\n",
      "Score: 0.0008444114937447011\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 582\n",
      "units_1: 679\n",
      "units_2: 679\n",
      "units_3: 291\n",
      "units_4: 388\n",
      "Score: 0.0008446600986644626\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary(num_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dbbcb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 194)               19012     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 970)               189150    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 970)               941870    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 97)                94187     \n",
      "=================================================================\n",
      "Total params: 1,244,219\n",
      "Trainable params: 1,244,219\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get the top model\n",
    "models = tuner.get_best_models(num_models=10)\n",
    "best_model = models[0]\n",
    "\n",
    "# Build the best model\n",
    "best_model.build(input_shape=(None, 97))\n",
    "\n",
    "# Show the best model\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e3e554",
   "metadata": {},
   "source": [
    "Evaluate the best model and note the order of magnitude of the loss function for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b855088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 8.0795e-04\n"
     ]
    }
   ],
   "source": [
    "loss = best_model.evaluate(x_ts, y_ts, verbose=0)\n",
    "print(\"Loss = {:.4e}\".format(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb50e6a",
   "metadata": {},
   "source": [
    "### 5. Save the best model to file\n",
    "\n",
    "Tuning a network is computationally expensive. Besides, the results are not reproducible because of the stochastic nature of this mechanism. Therefore, we tune a network only once for a given data set and do not repeat it unless either the input shape or the data set itself has changed.\n",
    "\n",
    "Write the best model to file so that it can be loaded directly without repeating the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "783cdc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save(\"../output/model_3p.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
